{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwG2-9EZw_DF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Activation, BatchNormalization, Flatten\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fbjzNJ35qZ09"
   },
   "outputs": [],
   "source": [
    "vector_size = 1447\n",
    "event_num = 2\n",
    "droprate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZAJPAyuMqZ0-"
   },
   "outputs": [],
   "source": [
    "def DNN():\n",
    "    print(\"________DNN_________\")\n",
    "    train_input = Input(shape=(vector_size,), name='Inputlayer')\n",
    "    train_in = Dense(512, activation='relu')(train_input)\n",
    "    train_in = BatchNormalization()(train_in)\n",
    "    train_in = Dropout(droprate)(train_in)\n",
    "\n",
    "    train_in = Dense(256, activation='relu')(train_in)\n",
    "    train_in = BatchNormalization()(train_in)\n",
    "    train_in = Dropout(droprate)(train_in)\n",
    "\n",
    "    train_in = Dense(event_num)(train_in)\n",
    "    out = Activation('softmax')(train_in)\n",
    "\n",
    "    model = Model(train_input, out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5Z_DHXIkqZ0-"
   },
   "outputs": [],
   "source": [
    "def readdata():\n",
    "    #reading data\n",
    "    #dataset_path= '/dataset_piazza.csv' #piazza\n",
    "    #dataset_path= '/dataset_reznik.csv' #reznik\n",
    "    #dataset_path= '/dataset_stitch_ecoli_150.csv' #stitch_ecoli_150\n",
    "    #dataset_path= '/dataset_stitch_ecoli_400.csv' #stitch_ecoli_400\n",
    "    #dataset_path= '/dataset_stitch_ecoli_700.csv' #stitch_ecoli_700\n",
    "    #dataset_path= '/dataset_stitch_ecoli_900.csv' #stitch_ecoli_900\n",
    "    #dataset_path= '/dataset_stitch_yeast_150.csv' #stitch_yeast_150\n",
    "    #dataset_path= '/dataset_stitch_yeast_400.csv' #stitch_yeast_400\n",
    "    #dataset_path= '/dataset_stitch_yeast_700.csv' #stitch_yeast_700\n",
    "    dataset_path=  '/dataset_stitch_yeast_900.csv' #stitch_yeast_900\n",
    "    \n",
    "    all_matrix= []\n",
    "    all_labels= []\n",
    "\n",
    "\n",
    "    df= pd.read_csv(dataset_path, header=None)\n",
    "\n",
    "    df[df>2**32]=np.nan\n",
    "    df[df<-2**32]=np.nan\n",
    "    df= df.fillna(df.mean())\n",
    "    all= df.to_numpy(dtype= np.float64)\n",
    "    del df\n",
    "\n",
    "    \n",
    "    #pca\n",
    "    print(\"performing PCA\")\n",
    "    all_matrix= all[:, :-1]\n",
    "    \n",
    "    #all_labels= np.array(all_labels)\n",
    "    all_labels= all[:, -1]\n",
    "    \n",
    "    print(all_matrix.shape)\n",
    "    print(all_labels.shape)\n",
    "    pca= PCA(n_components= 1447)\n",
    "    print(\"fitting PCA and transforming origin matrix with shape:\\t\", all_matrix.shape)\n",
    "    all_matrix= pca.fit_transform(all_matrix)\n",
    "    print(\"New matrix shape\", all_matrix.shape)\n",
    "\n",
    "\n",
    "    all_matrix, all_labels= shuffle(all_matrix, all_labels, random_state= 42)\n",
    "    all_matrix= list(all_matrix)\n",
    "    all_labels= list(all_labels)\n",
    "\n",
    " \n",
    "    return all_matrix, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Jkz0XAlGqZ0_"
   },
   "outputs": [],
   "source": [
    "def evaluate(pred_type, pred_score, y_test, event_num):\n",
    "    y_one_hot = label_binarize(y_test, classes= np.arange(event_num + 1))\n",
    "    y_one_hot = y_one_hot[:, [0, 1]]\n",
    "\n",
    "    result_auc_micro = roc_auc_score(y_one_hot, pred_score, average='micro')\n",
    "    result_auc_macro = roc_auc_score(y_one_hot, pred_score, average='macro')\n",
    "    return result_auc_micro, result_auc_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "KLZLzzmjqZ1A"
   },
   "outputs": [],
   "source": [
    "def get_index(label_matrix, event_num, seed, CV):\n",
    "    index_all_class = np.zeros(len(label_matrix))\n",
    "    for j in range(event_num):\n",
    "        index = np.where(label_matrix == j)\n",
    "        kf = KFold(n_splits=CV, shuffle=True, random_state=seed)\n",
    "        k_num = 0\n",
    "        for train_index, test_index in kf.split(range(len(index[0]))):\n",
    "            index_all_class[index[0][test_index]] = k_num\n",
    "            k_num += 1\n",
    "    return index_all_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "52qC0qmAqZ1B"
   },
   "outputs": [],
   "source": [
    "def cross_validation(feature_matrix, label_matrix, clf_type, event_num, seed, CV):\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    y_score = np.zeros((0, event_num), dtype=float)\n",
    "    label_matrix = np.array(label_matrix)\n",
    "    feature_matrix = np.array(feature_matrix)\n",
    "    index_all_class = get_index(label_matrix, event_num, seed, CV)\n",
    "\n",
    "    matrix = []\n",
    "    print(\"_____cross_validation_____\")\n",
    "\n",
    "    for k in range(CV):\n",
    "        train_index = np.where(index_all_class != k)\n",
    "        test_index = np.where(index_all_class == k)\n",
    "        pred = np.zeros((len(test_index[0]), event_num), dtype=float)\n",
    "\n",
    "        x_train = feature_matrix[train_index]\n",
    "        x_test = feature_matrix[test_index]\n",
    "        y_train = label_matrix[train_index]\n",
    "        y_test = label_matrix[test_index]\n",
    "\n",
    "        y_train_one_hot = np.array(y_train)\n",
    "        y_train_one_hot = (np.arange(y_train_one_hot.max() + 1) == y_train[:, None]).astype(dtype='float32')\n",
    "\n",
    "        y_test_one_hot = np.array(y_test)\n",
    "        y_test_one_hot = (np.arange(y_test_one_hot.max() + 1) == y_test[:, None]).astype(dtype='float32')\n",
    "\n",
    "        if clf_type == 'DNN':\n",
    "            dnn = DNN()\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "            dnn.fit(x_train, y_train_one_hot, batch_size=64, epochs=100, validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "            pred += dnn.predict(x_test)\n",
    "        else:\n",
    "            print(\"_______ERROR___________\")\n",
    "        pred_score = pred / 1\n",
    "        pred_type = np.argmax(pred_score, axis=1)\n",
    "        y_true = np.hstack((y_true, y_test))\n",
    "        y_pred = np.hstack((y_pred, pred_type))\n",
    "        y_score = np.row_stack((y_score, pred_score))\n",
    "\n",
    "        wfp = open(str(k) + '.txt', 'w')\n",
    "        for i in range(len(y_test)):\n",
    "            res = str(pred_score[i][0]) + ' ' + str(pred_score[i][1]) + ' ' + str(y_test[i]) + '\\n'\n",
    "            wfp.write(res)\n",
    "        wfp.close()\n",
    "\n",
    "        #########evaluate auc###########\n",
    "        result_micro, result_macro = evaluate(pred_type, pred_score, y_test, event_num)\n",
    "        print(\"idx, auc_micro, auc_macro: \", k, result_micro, result_macro)\n",
    "    result_all_micro, result_all_macro = evaluate(y_pred, y_score, y_true, event_num)\n",
    "    print(\"auc_micro_all, auc_macro_all: \", result_all_micro, result_all_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGinxdP1qZ1C",
    "outputId": "8a260121-1047-4ed7-9c93-c3d91041b762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing PCA\n",
      "(47150, 3475)\n",
      "(47150,)\n",
      "fitting PCA and transforming origin matrix with shape:\t (47150, 3475)\n",
      "New matrix shape (47150, 1447)\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "CV = 10\n",
    "all_matrix, all_labels = readdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNb98EuL4p8S",
    "outputId": "c556c5af-43ee-4952-8914-23851ad75b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____cross_validation_____\n",
      "________DNN_________\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1677 - accuracy: 0.9559 - val_loss: 0.0805 - val_accuracy: 0.9854\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0885 - accuracy: 0.9845 - val_loss: 0.0787 - val_accuracy: 0.9854\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0821 - accuracy: 0.9850 - val_loss: 0.0778 - val_accuracy: 0.9854\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0807 - accuracy: 0.9851 - val_loss: 0.0802 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0792 - accuracy: 0.9853 - val_loss: 0.0777 - val_accuracy: 0.9854\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0792 - accuracy: 0.9853 - val_loss: 0.0781 - val_accuracy: 0.9854\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0794 - accuracy: 0.9852 - val_loss: 0.0760 - val_accuracy: 0.9854\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0777 - accuracy: 0.9853 - val_loss: 0.0774 - val_accuracy: 0.9854\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0766 - accuracy: 0.9853 - val_loss: 0.0779 - val_accuracy: 0.9854\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9853 - val_loss: 0.0779 - val_accuracy: 0.9854\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0776 - accuracy: 0.9853 - val_loss: 0.0758 - val_accuracy: 0.9854\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0768 - accuracy: 0.9854 - val_loss: 0.0776 - val_accuracy: 0.9854\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0764 - val_accuracy: 0.9854\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0774 - accuracy: 0.9854 - val_loss: 0.0758 - val_accuracy: 0.9854\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9853 - val_loss: 0.0780 - val_accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9854 - val_loss: 0.0761 - val_accuracy: 0.9854\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.0756 - val_accuracy: 0.9854\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9855 - val_loss: 0.0757 - val_accuracy: 0.9854\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 0.0757 - val_accuracy: 0.9854\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 0.0768 - val_accuracy: 0.9854\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9854 - val_loss: 0.0761 - val_accuracy: 0.9854\n",
      "Epoch 22/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0760 - val_accuracy: 0.9854\n",
      "Epoch 23/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0756 - accuracy: 0.9854 - val_loss: 0.0757 - val_accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0750 - accuracy: 0.9854 - val_loss: 0.0777 - val_accuracy: 0.9854\n",
      "Epoch 25/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0751 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9854\n",
      "Epoch 26/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0754 - accuracy: 0.9854 - val_loss: 0.0837 - val_accuracy: 0.9854\n",
      "Epoch 27/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0752 - accuracy: 0.9854 - val_loss: 0.0809 - val_accuracy: 0.9854\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  0 0.9886195802857614 0.6127359711579545\n",
      "________DNN_________\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1573 - accuracy: 0.9585 - val_loss: 0.0804 - val_accuracy: 0.9854\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0857 - accuracy: 0.9846 - val_loss: 0.0846 - val_accuracy: 0.9854\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0834 - accuracy: 0.9849 - val_loss: 0.0815 - val_accuracy: 0.9854\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0813 - accuracy: 0.9851 - val_loss: 0.0795 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0792 - accuracy: 0.9853 - val_loss: 0.0795 - val_accuracy: 0.9854\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0792 - accuracy: 0.9852 - val_loss: 0.0780 - val_accuracy: 0.9854\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0771 - accuracy: 0.9853 - val_loss: 0.0788 - val_accuracy: 0.9854\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0781 - accuracy: 0.9853 - val_loss: 0.0775 - val_accuracy: 0.9854\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9854 - val_loss: 0.0788 - val_accuracy: 0.9854\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0776 - accuracy: 0.9853 - val_loss: 0.0787 - val_accuracy: 0.9854\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9854 - val_loss: 0.0787 - val_accuracy: 0.9854\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9853 - val_loss: 0.0814 - val_accuracy: 0.9854\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0776 - accuracy: 0.9854 - val_loss: 0.0777 - val_accuracy: 0.9854\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0773 - val_accuracy: 0.9854\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0762 - accuracy: 0.9855 - val_loss: 0.0774 - val_accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0763 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9854\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0767 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9854\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0757 - accuracy: 0.9854 - val_loss: 0.0784 - val_accuracy: 0.9854\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0762 - accuracy: 0.9853 - val_loss: 0.0772 - val_accuracy: 0.9854\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0753 - accuracy: 0.9855 - val_loss: 0.0753 - val_accuracy: 0.9854\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0754 - accuracy: 0.9854 - val_loss: 0.0781 - val_accuracy: 0.9854\n",
      "Epoch 22/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.0776 - val_accuracy: 0.9854\n",
      "Epoch 23/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0786 - val_accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.0774 - val_accuracy: 0.9854\n",
      "Epoch 25/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0751 - accuracy: 0.9854 - val_loss: 0.0763 - val_accuracy: 0.9854\n",
      "Epoch 26/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9854 - val_loss: 0.0777 - val_accuracy: 0.9854\n",
      "Epoch 27/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0754 - accuracy: 0.9854 - val_loss: 0.0807 - val_accuracy: 0.9854\n",
      "Epoch 28/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0753 - accuracy: 0.9855 - val_loss: 0.0762 - val_accuracy: 0.9854\n",
      "Epoch 29/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0756 - accuracy: 0.9855 - val_loss: 0.0784 - val_accuracy: 0.9854\n",
      "Epoch 30/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 0.0780 - val_accuracy: 0.9854\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  1 0.988293960393974 0.6014430378957283\n",
      "________DNN_________\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1620 - accuracy: 0.9572 - val_loss: 0.0805 - val_accuracy: 0.9854\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0874 - accuracy: 0.9845 - val_loss: 0.0781 - val_accuracy: 0.9854\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0825 - accuracy: 0.9850 - val_loss: 0.0804 - val_accuracy: 0.9854\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0806 - accuracy: 0.9852 - val_loss: 0.0751 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0800 - accuracy: 0.9853 - val_loss: 0.0744 - val_accuracy: 0.9854\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0785 - accuracy: 0.9852 - val_loss: 0.0719 - val_accuracy: 0.9854\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0788 - accuracy: 0.9854 - val_loss: 0.0733 - val_accuracy: 0.9854\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9854 - val_loss: 0.0723 - val_accuracy: 0.9854\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9853 - val_loss: 0.0747 - val_accuracy: 0.9854\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0787 - accuracy: 0.9852 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9853 - val_loss: 0.0742 - val_accuracy: 0.9854\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0767 - accuracy: 0.9853 - val_loss: 0.0730 - val_accuracy: 0.9854\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0771 - accuracy: 0.9855 - val_loss: 0.0761 - val_accuracy: 0.9854\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9853 - val_loss: 0.0737 - val_accuracy: 0.9854\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0768 - accuracy: 0.9854 - val_loss: 0.0720 - val_accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  2 0.9878604075347418 0.5864068449958365\n",
      "________DNN_________\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1642 - accuracy: 0.9541 - val_loss: 0.0765 - val_accuracy: 0.9854\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0861 - accuracy: 0.9846 - val_loss: 0.0760 - val_accuracy: 0.9854\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0832 - accuracy: 0.9851 - val_loss: 0.0748 - val_accuracy: 0.9854\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0807 - accuracy: 0.9852 - val_loss: 0.0746 - val_accuracy: 0.9854\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0798 - accuracy: 0.9851 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0789 - accuracy: 0.9854 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0791 - accuracy: 0.9853 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0788 - accuracy: 0.9853 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9853 - val_loss: 0.0761 - val_accuracy: 0.9854\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0777 - accuracy: 0.9852 - val_loss: 0.0749 - val_accuracy: 0.9854\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0791 - accuracy: 0.9852 - val_loss: 0.0741 - val_accuracy: 0.9854\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0770 - accuracy: 0.9854 - val_loss: 0.0737 - val_accuracy: 0.9854\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9854 - val_loss: 0.0741 - val_accuracy: 0.9854\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0749 - val_accuracy: 0.9854\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9855 - val_loss: 0.0750 - val_accuracy: 0.9854\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0736 - val_accuracy: 0.9854\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9855 - val_loss: 0.0731 - val_accuracy: 0.9854\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.0742 - val_accuracy: 0.9854\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0760 - accuracy: 0.9855 - val_loss: 0.0745 - val_accuracy: 0.9854\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0760 - val_accuracy: 0.9854\n",
      "Epoch 22/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0751 - accuracy: 0.9855 - val_loss: 0.0776 - val_accuracy: 0.9854\n",
      "Epoch 23/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.0758 - accuracy: 0.9855 - val_loss: 0.0747 - val_accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 0.0755 - val_accuracy: 0.9854\n",
      "Epoch 25/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0765 - accuracy: 0.9854 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
      "Epoch 26/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0757 - accuracy: 0.9855 - val_loss: 0.0736 - val_accuracy: 0.9854\n",
      "Epoch 27/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9855 - val_loss: 0.0750 - val_accuracy: 0.9854\n",
      "Epoch 28/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9854 - val_loss: 0.0730 - val_accuracy: 0.9854\n",
      "Epoch 29/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
      "Epoch 30/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 0.0732 - val_accuracy: 0.9854\n",
      "Epoch 31/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9855 - val_loss: 0.0733 - val_accuracy: 0.9854\n",
      "Epoch 32/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0754 - accuracy: 0.9855 - val_loss: 0.0752 - val_accuracy: 0.9854\n",
      "Epoch 33/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0757 - accuracy: 0.9855 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
      "Epoch 34/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9854 - val_loss: 0.0737 - val_accuracy: 0.9854\n",
      "Epoch 35/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9854 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
      "Epoch 36/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9855 - val_loss: 0.0746 - val_accuracy: 0.9854\n",
      "Epoch 37/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 0.0742 - val_accuracy: 0.9854\n",
      "Epoch 38/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9855 - val_loss: 0.0744 - val_accuracy: 0.9854\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  3 0.9898300436821648 0.6547164603624591\n",
      "________DNN_________\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1600 - accuracy: 0.9576 - val_loss: 0.0856 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0846 - accuracy: 0.9849 - val_loss: 0.0830 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0817 - accuracy: 0.9851 - val_loss: 0.0802 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0802 - accuracy: 0.9851 - val_loss: 0.0793 - val_accuracy: 0.9856\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0789 - accuracy: 0.9852 - val_loss: 0.0819 - val_accuracy: 0.9856\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0783 - accuracy: 0.9853 - val_loss: 0.0803 - val_accuracy: 0.9856\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0777 - accuracy: 0.9853 - val_loss: 0.0794 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9854 - val_loss: 0.0779 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9854 - val_loss: 0.0763 - val_accuracy: 0.9856\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0781 - accuracy: 0.9853 - val_loss: 0.0797 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0776 - accuracy: 0.9852 - val_loss: 0.0788 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9853 - val_loss: 0.0804 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0771 - accuracy: 0.9853 - val_loss: 0.0772 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.0789 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0777 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9853 - val_loss: 0.0786 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0766 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0758 - accuracy: 0.9855 - val_loss: 0.0746 - val_accuracy: 0.9856\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9854 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9854 - val_loss: 0.0773 - val_accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0758 - accuracy: 0.9854 - val_loss: 0.0766 - val_accuracy: 0.9856\n",
      "Epoch 22/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9854 - val_loss: 0.0776 - val_accuracy: 0.9856\n",
      "Epoch 23/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0758 - val_accuracy: 0.9856\n",
      "Epoch 24/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9854 - val_loss: 0.0752 - val_accuracy: 0.9856\n",
      "Epoch 25/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0752 - accuracy: 0.9854 - val_loss: 0.0767 - val_accuracy: 0.9856\n",
      "Epoch 26/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0757 - accuracy: 0.9854 - val_loss: 0.0793 - val_accuracy: 0.9856\n",
      "Epoch 27/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0748 - val_accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9855 - val_loss: 0.0758 - val_accuracy: 0.9856\n",
      "Epoch 29/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0749 - accuracy: 0.9855 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  4 0.9892335442603816 0.6285910264686895\n",
      "________DNN_________\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1604 - accuracy: 0.9565 - val_loss: 0.0814 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0832 - accuracy: 0.9851 - val_loss: 0.0785 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0836 - accuracy: 0.9851 - val_loss: 0.0792 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0796 - accuracy: 0.9852 - val_loss: 0.0783 - val_accuracy: 0.9856\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0800 - accuracy: 0.9853 - val_loss: 0.0784 - val_accuracy: 0.9856\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0798 - accuracy: 0.9852 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0798 - accuracy: 0.9852 - val_loss: 0.0783 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0780 - accuracy: 0.9852 - val_loss: 0.0771 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9853 - val_loss: 0.0786 - val_accuracy: 0.9856\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0780 - accuracy: 0.9853 - val_loss: 0.0758 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.9854 - val_loss: 0.0768 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0763 - accuracy: 0.9854 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9853 - val_loss: 0.0761 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0771 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0768 - accuracy: 0.9855 - val_loss: 0.0772 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.0772 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0765 - accuracy: 0.9853 - val_loss: 0.0776 - val_accuracy: 0.9856\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9854 - val_loss: 0.0756 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 3s 4ms/step - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.0787 - val_accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0767 - accuracy: 0.9854 - val_loss: 0.0759 - val_accuracy: 0.9856\n",
      "Epoch 22/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0767 - val_accuracy: 0.9856\n",
      "Epoch 23/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0763 - val_accuracy: 0.9856\n",
      "Epoch 24/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 0.0750 - val_accuracy: 0.9856\n",
      "Epoch 25/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9854 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "Epoch 26/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9855 - val_loss: 0.0760 - val_accuracy: 0.9856\n",
      "Epoch 27/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0756 - val_accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.0763 - val_accuracy: 0.9856\n",
      "Epoch 29/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0765 - val_accuracy: 0.9856\n",
      "Epoch 30/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0757 - accuracy: 0.9854 - val_loss: 0.0804 - val_accuracy: 0.9856\n",
      "Epoch 31/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0762 - accuracy: 0.9854 - val_loss: 0.0759 - val_accuracy: 0.9856\n",
      "Epoch 32/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0756 - val_accuracy: 0.9856\n",
      "Epoch 33/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9854 - val_loss: 0.0753 - val_accuracy: 0.9856\n",
      "Epoch 34/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0758 - accuracy: 0.9854 - val_loss: 0.0757 - val_accuracy: 0.9856\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  5 0.9887866727991822 0.6128716819200244\n",
      "________DNN_________\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1611 - accuracy: 0.9562 - val_loss: 0.0805 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0866 - accuracy: 0.9845 - val_loss: 0.0746 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0827 - accuracy: 0.9850 - val_loss: 0.0754 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0801 - accuracy: 0.9852 - val_loss: 0.0749 - val_accuracy: 0.9856\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0792 - accuracy: 0.9852 - val_loss: 0.0773 - val_accuracy: 0.9856\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0796 - accuracy: 0.9854 - val_loss: 0.0755 - val_accuracy: 0.9856\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0790 - accuracy: 0.9852 - val_loss: 0.0742 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9853 - val_loss: 0.0742 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.9853 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0787 - accuracy: 0.9853 - val_loss: 0.0753 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9853 - val_loss: 0.0745 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9854 - val_loss: 0.0745 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9854 - val_loss: 0.0749 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9854 - val_loss: 0.0748 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9855 - val_loss: 0.0740 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0738 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9853 - val_loss: 0.0743 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0740 - val_accuracy: 0.9856\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0764 - accuracy: 0.9853 - val_loss: 0.0747 - val_accuracy: 0.9856\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  6 0.9888725240750118 0.6159750006330555\n",
      "________DNN_________\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 5s 6ms/step - loss: 0.1576 - accuracy: 0.9578 - val_loss: 0.0791 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0870 - accuracy: 0.9848 - val_loss: 0.0745 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0819 - accuracy: 0.9852 - val_loss: 0.0725 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0799 - accuracy: 0.9853 - val_loss: 0.0735 - val_accuracy: 0.9856\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0797 - accuracy: 0.9852 - val_loss: 0.0724 - val_accuracy: 0.9856\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0791 - accuracy: 0.9852 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0782 - accuracy: 0.9854 - val_loss: 0.0724 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0790 - accuracy: 0.9853 - val_loss: 0.0718 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0780 - accuracy: 0.9852 - val_loss: 0.0771 - val_accuracy: 0.9856\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0779 - accuracy: 0.9853 - val_loss: 0.0728 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0775 - accuracy: 0.9853 - val_loss: 0.0719 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9853 - val_loss: 0.0722 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9853 - val_loss: 0.0735 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9854 - val_loss: 0.0731 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0781 - accuracy: 0.9853 - val_loss: 0.0733 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.0730 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0768 - accuracy: 0.9854 - val_loss: 0.0757 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9854 - val_loss: 0.0730 - val_accuracy: 0.9856\n",
      "148/148 [==============================] - 0s 3ms/step\n",
      "idx, auc_micro, auc_macro:  7 0.9903253544402982 0.6670697120862981\n",
      "________DNN_________\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 5s 6ms/step - loss: 0.1601 - accuracy: 0.9571 - val_loss: 0.0790 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0862 - accuracy: 0.9846 - val_loss: 0.0790 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0818 - accuracy: 0.9849 - val_loss: 0.0820 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0809 - accuracy: 0.9852 - val_loss: 0.0792 - val_accuracy: 0.9856\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0790 - accuracy: 0.9853 - val_loss: 0.0766 - val_accuracy: 0.9856\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9852 - val_loss: 0.0776 - val_accuracy: 0.9856\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0782 - accuracy: 0.9853 - val_loss: 0.0784 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0785 - accuracy: 0.9853 - val_loss: 0.0760 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0778 - accuracy: 0.9854 - val_loss: 0.0807 - val_accuracy: 0.9856\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0779 - accuracy: 0.9854 - val_loss: 0.0803 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9854 - val_loss: 0.0752 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9854 - val_loss: 0.0763 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9853 - val_loss: 0.0795 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9854 - val_loss: 0.0772 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.0772 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0774 - accuracy: 0.9854 - val_loss: 0.0770 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9853 - val_loss: 0.0777 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9853 - val_loss: 0.0783 - val_accuracy: 0.9856\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0773 - accuracy: 0.9854 - val_loss: 0.0769 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0763 - accuracy: 0.9853 - val_loss: 0.0777 - val_accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0763 - accuracy: 0.9854 - val_loss: 0.0766 - val_accuracy: 0.9856\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  8 0.9884478059289177 0.6010380529740953\n",
      "________DNN_________\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 1447)]            0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 512)               741376    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 876,290\n",
      "Trainable params: 874,754\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.1608 - accuracy: 0.9569 - val_loss: 0.0839 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0853 - accuracy: 0.9848 - val_loss: 0.0778 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0829 - accuracy: 0.9851 - val_loss: 0.0781 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0800 - accuracy: 0.9852 - val_loss: 0.0771 - val_accuracy: 0.9856\n",
      "Epoch 5/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0811 - accuracy: 0.9852 - val_loss: 0.0763 - val_accuracy: 0.9856\n",
      "Epoch 6/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0793 - accuracy: 0.9852 - val_loss: 0.0745 - val_accuracy: 0.9856\n",
      "Epoch 7/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0788 - accuracy: 0.9852 - val_loss: 0.0755 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9852 - val_loss: 0.0774 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0780 - accuracy: 0.9852 - val_loss: 0.0757 - val_accuracy: 0.9856\n",
      "Epoch 10/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0772 - accuracy: 0.9854 - val_loss: 0.0744 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0784 - accuracy: 0.9853 - val_loss: 0.0750 - val_accuracy: 0.9856\n",
      "Epoch 12/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0741 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0773 - accuracy: 0.9853 - val_loss: 0.0771 - val_accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0771 - accuracy: 0.9853 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "Epoch 15/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9855 - val_loss: 0.0741 - val_accuracy: 0.9856\n",
      "Epoch 16/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9854 - val_loss: 0.0748 - val_accuracy: 0.9856\n",
      "Epoch 17/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0768 - accuracy: 0.9854 - val_loss: 0.0766 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.0742 - val_accuracy: 0.9856\n",
      "Epoch 19/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.0761 - accuracy: 0.9854 - val_loss: 0.0755 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0768 - accuracy: 0.9854 - val_loss: 0.0759 - val_accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9853 - val_loss: 0.0761 - val_accuracy: 0.9856\n",
      "Epoch 22/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0767 - accuracy: 0.9854 - val_loss: 0.0758 - val_accuracy: 0.9856\n",
      "Epoch 23/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9854 - val_loss: 0.0746 - val_accuracy: 0.9856\n",
      "Epoch 24/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0759 - accuracy: 0.9854 - val_loss: 0.0749 - val_accuracy: 0.9856\n",
      "Epoch 25/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9854 - val_loss: 0.0732 - val_accuracy: 0.9856\n",
      "Epoch 26/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0766 - accuracy: 0.9853 - val_loss: 0.0758 - val_accuracy: 0.9856\n",
      "Epoch 27/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0770 - accuracy: 0.9853 - val_loss: 0.0741 - val_accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0760 - accuracy: 0.9853 - val_loss: 0.0747 - val_accuracy: 0.9856\n",
      "Epoch 29/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0760 - accuracy: 0.9854 - val_loss: 0.0781 - val_accuracy: 0.9856\n",
      "Epoch 30/100\n",
      "664/664 [==============================] - 4s 6ms/step - loss: 0.0760 - accuracy: 0.9854 - val_loss: 0.0742 - val_accuracy: 0.9856\n",
      "Epoch 31/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0756 - accuracy: 0.9854 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
      "Epoch 32/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0815 - val_accuracy: 0.9856\n",
      "Epoch 33/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0735 - val_accuracy: 0.9856\n",
      "Epoch 34/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9854 - val_loss: 0.0726 - val_accuracy: 0.9856\n",
      "Epoch 35/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9855 - val_loss: 0.0752 - val_accuracy: 0.9856\n",
      "Epoch 36/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0758 - accuracy: 0.9855 - val_loss: 0.0734 - val_accuracy: 0.9856\n",
      "Epoch 37/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0753 - accuracy: 0.9855 - val_loss: 0.0736 - val_accuracy: 0.9856\n",
      "Epoch 38/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0750 - accuracy: 0.9855 - val_loss: 0.0753 - val_accuracy: 0.9856\n",
      "Epoch 39/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0748 - accuracy: 0.9855 - val_loss: 0.0742 - val_accuracy: 0.9856\n",
      "Epoch 40/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0755 - accuracy: 0.9854 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
      "Epoch 41/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0754 - accuracy: 0.9854 - val_loss: 0.0726 - val_accuracy: 0.9856\n",
      "Epoch 42/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0749 - accuracy: 0.9855 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
      "Epoch 43/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0752 - accuracy: 0.9855 - val_loss: 0.0738 - val_accuracy: 0.9856\n",
      "Epoch 44/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0752 - accuracy: 0.9854 - val_loss: 0.0729 - val_accuracy: 0.9856\n",
      "Epoch 45/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0749 - accuracy: 0.9854 - val_loss: 0.0734 - val_accuracy: 0.9856\n",
      "Epoch 46/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0750 - accuracy: 0.9855 - val_loss: 0.0758 - val_accuracy: 0.9856\n",
      "Epoch 47/100\n",
      "664/664 [==============================] - 4s 7ms/step - loss: 0.0748 - accuracy: 0.9855 - val_loss: 0.0744 - val_accuracy: 0.9856\n",
      "Epoch 48/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0749 - accuracy: 0.9854 - val_loss: 0.0729 - val_accuracy: 0.9856\n",
      "Epoch 49/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9855 - val_loss: 0.0753 - val_accuracy: 0.9856\n",
      "Epoch 50/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0747 - accuracy: 0.9855 - val_loss: 0.0725 - val_accuracy: 0.9856\n",
      "Epoch 51/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0744 - accuracy: 0.9854 - val_loss: 0.0734 - val_accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "664/664 [==============================] - 4s 5ms/step - loss: 0.0745 - accuracy: 0.9855 - val_loss: 0.0735 - val_accuracy: 0.9856\n",
      "Epoch 53/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0747 - accuracy: 0.9855 - val_loss: 0.0749 - val_accuracy: 0.9856\n",
      "Epoch 54/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0746 - accuracy: 0.9855 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
      "Epoch 55/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0749 - accuracy: 0.9855 - val_loss: 0.0730 - val_accuracy: 0.9856\n",
      "Epoch 56/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0749 - accuracy: 0.9855 - val_loss: 0.0735 - val_accuracy: 0.9856\n",
      "Epoch 57/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0746 - accuracy: 0.9855 - val_loss: 0.0759 - val_accuracy: 0.9856\n",
      "Epoch 58/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0745 - accuracy: 0.9855 - val_loss: 0.0739 - val_accuracy: 0.9856\n",
      "Epoch 59/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0737 - accuracy: 0.9855 - val_loss: 0.0905 - val_accuracy: 0.9856\n",
      "Epoch 60/100\n",
      "664/664 [==============================] - 3s 5ms/step - loss: 0.0745 - accuracy: 0.9855 - val_loss: 0.0746 - val_accuracy: 0.9856\n",
      "148/148 [==============================] - 0s 2ms/step\n",
      "idx, auc_micro, auc_macro:  9 0.990380480497616 0.6690084449621434\n",
      "auc_micro_all, auc_macro_all:  0.9877023378153926 0.5772650482916137\n",
      "F1 Macro 0.4963467783284909\n",
      "Accuracy: 0.9854931071049841\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([])\n",
    "y_pred = np.array([])\n",
    "y_score = np.zeros((0, event_num), dtype=float)\n",
    "label_matrix = np.array(all_labels)\n",
    "feature_matrix = np.array(all_matrix)\n",
    "index_all_class = get_index(label_matrix, event_num, seed, CV)\n",
    "\n",
    "matrix = []\n",
    "print(\"_____cross_validation_____\")\n",
    "\n",
    "for k in range(CV):\n",
    "    train_index = np.where(index_all_class != k)\n",
    "    test_index = np.where(index_all_class == k)\n",
    "    pred = np.zeros((len(test_index[0]), event_num), dtype=float)\n",
    "\n",
    "    x_train = feature_matrix[train_index]\n",
    "    x_test = feature_matrix[test_index]\n",
    "    y_train = label_matrix[train_index]\n",
    "    y_test = label_matrix[test_index]\n",
    "\n",
    "    y_train_one_hot = np.array(y_train)\n",
    "    y_train_one_hot = (np.arange(y_train_one_hot.max() + 1) == y_train[:, None]).astype(dtype='float32')\n",
    "\n",
    "    y_test_one_hot = np.array(y_test)\n",
    "    y_test_one_hot = (np.arange(y_test_one_hot.max() + 1) == y_test[:, None]).astype(dtype='float32')\n",
    "\n",
    "\n",
    "    dnn = DNN()\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "    dnn.fit(x_train, y_train_one_hot, batch_size=64, epochs=100, validation_data=(x_test, y_test_one_hot),\n",
    "            callbacks=[early_stopping])\n",
    "\n",
    "    pred += dnn.predict(x_test)\n",
    "\n",
    "    pred_score = pred / 1\n",
    "    pred_type = np.argmax(pred_score, axis=1)\n",
    "    y_true = np.hstack((y_true, y_test))\n",
    "    y_pred = np.hstack((y_pred, pred_type))\n",
    "    y_score = np.row_stack((y_score, pred_score))\n",
    "\n",
    "    wfp = open(str(k) + '.txt', 'w')\n",
    "    for i in range(len(y_test)):\n",
    "        res = str(pred_score[i][0]) + ' ' + str(pred_score[i][1]) + ' ' + str(y_test[i]) + '\\n'\n",
    "        wfp.write(res)\n",
    "    wfp.close()\n",
    "\n",
    "    #########evaluate auc###########\n",
    "    result_micro, result_macro = evaluate(pred_type, pred_score, y_test, event_num)\n",
    "    print(\"idx, auc_micro, auc_macro: \", k, result_micro, result_macro)\n",
    "result_all_micro, result_all_macro = evaluate(y_pred, y_score, y_true, event_num)\n",
    "print(\"auc_macro_all: \", result_all_macro)\n",
    "print(\"F1 Macro\", f1_score(y_true, y_pred, average='macro'))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4ELTKPaIbH6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
