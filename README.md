# SARTRE (ShAdow pRice - based meTabolite pRotein intEraction)
## Integration of machine learning and constraint-based modeling accurately predicts metabolite-protein interactions

SARTRE framework investigates the power of shadow prices which are calculated based on constraint-based modeling of genome-scale metabolic models(GEMs). SARTRE framework investigates the power of shadow prices which are calculated based on constraint-based modeling of genome-scale metabolic models. We can separate the framework into five stages:

### 1. Curating the GEMs:
Two models have been used in this study. 
- [iJO1366](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3261703/): A comprehensive genome-scale reconstruction of *Escherichia coli* metabolism
- [Yeast-GEM](https://github.com/SysBioChalmers/yeast-GEM): A consensus *S. cerevisiae* metabolic model Yeast8 and its ecosystem for comprehensively probing cellular metabolism
Curation of these mentioned GEMs have been performed by the  COBRAToolbox in MATLAB. `modelPreparing_iJO1366.m` uses `iJO1366.mat` as the input and creates `ModelIrrevOpt90.mat` and  `modelPreparing_yeastGEM.m` uses `Yeast-GEM.mat` and creates `yeast_IrrevOpt90.mat`.

### 2. Calculating shadow prices
In this study, we employed four gold standards integrated to GEMs as:
- [piazza](https://pubmed.ncbi.nlm.nih.gov/29307493/)
- [reznik](https://pubmed.ncbi.nlm.nih.gov/28903046/)
- [stitch_ecoli](http://stitch.embl.de/)
- [stitch_yeast](http://stitch.embl.de/)

The optimization process has been implemented by [GUROBI](https://www.gurobi.com/) optimizer and its python interface. Make sure to be installed and have an active license for it beforehand. Calculation of shadow prices can be performed in their directory by changing the working directory followed by executing `optimization.py`. For instance, the process for `piazza` can be done by following commands in the terminal:
```
cd piazza
python3 optimization.py
```
The results of optimization will be saved on the `opt` directory for each reaction by its number. The process is the same for other gold standards. Also the results are provided in the `.zip` archive in their directory.

### 3. Data pre-processing
The framework is followed by preprocessing calculated shadow prices for downstream classifiers changing the directory to specific gold standard and executing `cleaning.py`. Also, in this stage, fingerprints of size 128 bits can be generated by executing `generate_fp.py`. make sure to have installed [RDKit](https://www.rdkit.org/) in your environment. For example for `piazza` gold standard the process can be done by executing following commands in the terminal:
```
cd piazza
python3 cleaning.py
python3 generate_fp.py
```
`generate_fp.py` prompts you to enter your email for using the [Bio.Entrez](https://biopython.org/docs/1.76/api/Bio.Entrez.html) package. The results will be saved in `met_sps_t80_replaced.csv` and `met_fp128.csv`, respectively.

### 4. Training classifier and evaluation
Preprocessing, constructing datasets, training the random forest classifier and evaluating it can be executed by running `evaluate.py` in each gold standard directory. The classifier and metrics are employed from [sklearn](https://scikit-learn.org/stable/) python library. For example, for `piazza` gold standard the process can be done for using shadow prices and fingerprints, respectively, by executing:
```
cd piazza
python3 evaluate.py sp
python3 evaluate.py fp
```
Gold standard from STITCH also gets an additional argument as a confidence score(150: low, 400: medium, 700: high, 900: highest) to perform this process. for example, for `stitch_ecoli` and using medium confidence score and shadow price as metabolite features:
```
cd stitch_ecoli
python3 evaluate.py sp 400 
```

### 5. Performance of SARTRE on specific tasks 
Additional evaluation has been provided to showcase the power of SARTRE. First, evaluation has been done by excluding shared metabolite-protein pairs, which exist in two GEMs, from the datasets, and training two separate models in remaining pairs. This can be performed by executing:
```
cd subsys_shared
python3 shared.py
```
The accuracy of two models on the test set and cosine similarity of predictions to classifiers will be displayed.
Second, we excluded metabolite-protein pairs of two subsystems of *E. coli* separately from stitch_ecoli and trained two models on remaining pairs. These subsystems are Alternate Carbon Metabolism and Cofactor and Prosthetic Group Biosynthesis. This process can be done by executing:
```
cd subsys_shared
python3 subsys.py acm
python3 subsys.py cpgb
```

### Additional analyses:

### 1. Comparison with existing MPI predictions.
In this analysis SARTRE predictions are compared to computational predictions by [Zhao et al.](https://academic.oup.com/bib/article-abstract/22/5/bbab014/6130169?redirectedFrom=fulltext). The datasets are constructed based on the method for pairs of our datasets and evaluation with 10-fold cross validation is applied. The deep neural network and constructed datasets are available in the comparison folder.

### 2. Performance of SARTRE in different media compositions
In this part SARTRE framework is applied to a dataset, which is constructed from the GEM of iJO1366 and the gold standard from STITCH with a medium (400) confidence score. We utilized models with different carbon sources as acetate, fructose, glycerol, mannose, and succinate, and compared metrics with the base model, which was in glucose media composition. Also, the code is available for different carbon/nitrogen/phosphorus sources with limiting and non-limiting values. In each directory, the manipulated model, results of optimization and metabolite/protein features are accessible.
 For executing the codes, first, change current directory, then run the script with desired setting name, e.g. acetate as below:

```
cd media_composition
python3 evaluation.py acetate
```

### 3. Investigation of MPI relations of GEM through datasets
In this part, evaluation of SARTRE without shared MPIs between GEM and gold standards is performed. To execute the codes, change the directory to desired dataset and run evaluate_without.py in the command line, e.g. for piazza:

```
cd piazza
python3 evaluate_without.py
```
For STITCH derived datasets, run the commands with desired confidence score as a first argument, e.g. stitch_ecoli with medium confidence score(400):
```
cd stitch_ecoli
python3 evaluate_without.py 400
```

### 4. Permutation tests:
We examined the performance of SARTRE with two permutation tests of label permutation and feature permutation. To run the codes, first change directory to each datasets and execute python code permutation_tests.py with two label_permutation/feature_permutation options e.g. for piazza and lable permutation test:
```
cd piazza
python3 permutation_tests.py label_permutation
```
For STITCH derived datasets, run the commands with desired confidence score as a first argument, e.g. stitch_ecoli with medium confidence score(400) and feature permutation test:
```
cd stitch_ecoli
python3 permutation_tests.py 400 feature_permutation
```

***MAKE sure to unzip archives***


## Citation
```
# Cross-Modality and Self-Supervised Protein Embedding for Compound-Protein Affinity and Contact Prediction

## Motivation
Computational methods for compound-protein affinity and contact (CPAC) prediction aim at facilitating rational drug discovery by simultaneous prediction of the strength and the pattern of compound-protein interactions. Although the desired outputs are highly structure-dependent, the lack of protein   structures often force structure-free methods to rely on protein sequence inputs alone.  The scarcity of compound-protein pairs with affinity and contact labels further limits the accuracy and the generalizability of CPAC models.

## Results
To overcome the aforementioned challenges of structure naivety and labeled-data scarcity, we, for the first time, introduce cross-modality and self-supervised learning, respectively, for structure-aware and task-relevant protein embedding.  Specifically, protein data are  available in both modalities of 1D amino-acid sequences and predicted 2D contact maps, that are separately embedded with recurrent and graph neural networks, respectively, as well as jointly embedded with two cross-modality schemes.  Furthermore, both protein modalities are pretrained under various self-supervised learning strategies, by leveraging massive amount of unlabeled protein data.  Our results indicate that individual protein modalities differ in their strengths of predicting affinities or contacts.  Proper cross-modality protein embedding combined with self-supervised learning improves model  generalizability when predicting both affinities and contacts for unseen proteins. 

## Data
Please download the processed data from https://drive.google.com/file/d/1jvMHKpmg-iU8uqfJrmU-MQHSP_e46a-k/view?usp=sharing and https://drive.google.com/file/d/19g9jUt4BF_-MouUooqzs6iGIslWG-mmJ/view?usp=sharing, and extract them by:
```
unzip data.zip
unzip pretrain_data.zip
```

## Experiments
* Cross-modality protein embeddings [[keras]](https://github.com/Shen-Lab/CPAC/tree/main/cross_modality_keras) [[pytorch]](https://github.com/Shen-Lab/CPAC/tree/main/cross_modality_torch)
* [Pre-training with MLM and GraphComp](https://github.com/Shen-Lab/CPAC/tree/main/pretrain_torch)
* [Finetuning](https://github.com/Shen-Lab/CPAC/tree/main/finetune_torch)

## Discussions
* For the contact prediction training, we use the [regression loss](https://github.com/Shen-Lab/CPAC/blob/d1c7eb2291d79433ab70aa98eb1dbceb72ff6b07/cross_modality_torch/main_concatenation_parallel.py#L150) (where the ground-truth, binary contact matrix was [normalized](https://github.com/Shen-Lab/CPAC/blob/d1c7eb2291d79433ab70aa98eb1dbceb72ff6b07/cross_modality_torch/main_concatenation_parallel.py#L83)) rather than the standard [classification loss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html).
We find that regression loss provides great benefits on precision evaluation (see supplemental results for evidence). One might opt to the loss of the standard binary cross entropy with a non-normalized, binary ground-truth contact matrix, by modifying the codes in the above linked lines. 

## Featurization
To process raw data into input formats of CPAC, we follow the same procedure as in DeepRelations (https://pubs.acs.org/doi/full/10.1021/acs.jcim.0c00866#) with the detailed description in its supplement (https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.0c00866/suppl_file/ci0c00866_si_001.pdf). We further provide a utils file for this purpose: https://github.com/Shen-Lab/CPAC/blob/main/featurization_utils.py.

High-level summary of the featurization:

Proteins graph: Residues as nodes, and edges justified by spatial distances of C-alpha atoms
- Node feature: One-hot embedding of the residue types (mapping dictionary: https://github.com/Shen-Lab/CPAC/blob/bc7fc71e30df7758b3ace2301e00d5f82d4d3965/featurization_utils.py#L2)
- Edges: If structures are present, the adjacency matrix is constructed with a_ij = 1 if  C-alpha distance <= 8 angstroms. If not, computational tools can be used to predict it (Section 1.3 in https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.0c00866/suppl_file/ci0c00866_si_001.pdf)

Compound graphs: Atoms as nodes and edge featurization would be more complicated considering chemical topology. A SMILES to compound graph function can be found at: https://github.com/Shen-Lab/CPAC/blob/bc7fc71e30df7758b3ace2301e00d5f82d4d3965/featurization_utils.py#L187.

## Citation

If you use this code for you research, please cite our paper.
```
@article{10.1093/bioinformatics/btac470,
    author = {You, Yuning and Shen, Yang},
    title = "{Cross-modality and self-supervised protein embedding for compoundâ€“protein affinity and contact prediction}",
    journal = {Bioinformatics},
    volume = {38},
    number = {Supplement_2},
    pages = {ii68-ii74},
    year = {2022},
    month = {09},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btac470},
    url = {https://doi.org/10.1093/bioinformatics/btac470},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/38/Supplement\_2/ii68/45884189/btac470.pdf},
}
```
